{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):   \n",
    "    return np.sqrt(np.sum((x - y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    return 1.0 - cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(x,y):\n",
    "    \n",
    "    return np.sum(np.absolute(x - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_distance(x,y):\n",
    "    return 0.5 * (np.sum(((x - y) ** 2) / (x + y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "N_Q = 1\n",
    "CONST_K = 1.25\n",
    "CONST_ANMRR = 0.5\n",
    "GT = [\"a_1\",\"a_9\",\"b_9\"]  #must be name of samples\n",
    "r = [\"9_a\", \"p_0\", \"ye_0\",\"k_9\",\"55_8\",\"a_1\",\"a_9\",\"b_9\"]\n",
    "\n",
    "print(type(GT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANMRR(all_query,all_GT):\n",
    "    total = 0.0\n",
    "    \n",
    "    for q in range(len(all_query)):\n",
    "        total = total + one_sample_nmrr(all_query[q], all_GT[q])\n",
    "        #print(\"ANMRR : \", total)\n",
    "        \n",
    "    return (1.0/len(all_query)) * total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sample_nmrr(q, GT):\n",
    "    part_1 = rank_mean(q, GT) - (CONST_ANMRR * (1.0 + len(GT)))\n",
    "    part_2 = (CONST_K * 2.0 * len(GT))- (CONST_ANMRR * (1.0 + len(GT)))\n",
    "    #print(\"rank_mean: \", rank_mean(q, GT))\n",
    "    #print(\"part_1:\" , part_1)\n",
    "    #print(\"part_2:\" ,part_2)\n",
    "    return part_1/part_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_mean(q, GT):\n",
    "    const_q = len(GT)\n",
    "    #print(\"rank_m (cons_q) :\" , const_q )\n",
    "    #print(\"sum_rank_q: \",sum_rank_q(q))\n",
    "   \n",
    "    return (1.0/const_q)*sum_rank_q(q, GT)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_rank_q(q, GT):\n",
    "    \n",
    "    total_pos = 0.0\n",
    "    penalty = 2 * CONST_K * (len(GT))\n",
    "    const_size = 2 *  (len(GT))\n",
    "    #print(const_size)\n",
    "    for j in range(len(GT)):\n",
    "        if q.index(GT[j]) <= const_size:\n",
    "            total_pos = total_pos + q.index(GT[j])+1\n",
    "            #print(\"sm :\",GT[j] )\n",
    "            #print(\"index :\",q.index(GT[j]) )\n",
    "        else:\n",
    "            total_pos = total_pos + penalty\n",
    "        #print(\"0\")\n",
    "                \n",
    "    #print(\"total_pos : \" , total_pos)\n",
    "    return total_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['9_a', 'p_0', 'ye_0', 'k_9', '55_8', 'a_1', 'a_9', 'b_9']\n",
      "0.878787878788\n"
     ]
    }
   ],
   "source": [
    "all_query = []\n",
    "all_GT = []\n",
    "all_query.append(r) # for retrieved image list\n",
    "#all_query.append(r)\n",
    "\n",
    "all_GT.append(GT) #for GT's\n",
    "\n",
    "print(len(all_query))\n",
    "\n",
    "print(all_query[0])\n",
    "\n",
    "print(ANMRR(all_query, all_GT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP(all_query, all_GT):\n",
    "    total = 0.0\n",
    "    size_Q = len(all_query)\n",
    "    \n",
    "    for q in range(len(all_query)):\n",
    "        total = total + precision_mean(all_query[q], all_GT[q])\n",
    "        #print(\"MAP : \", total) #0.4166\n",
    "        \n",
    "    return total/size_Q\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "def new_MAP(all_query, all_GT):\n",
    "    total = 0.0\n",
    "    size_Q = len(all_query)\n",
    "    #print(\"size_q :\" , size_Q)\n",
    "    for q in range(len(all_query)):\n",
    "        total = total + average_precision_score(all_query[q], all_GT[q])\n",
    "        #print(\"MAP : \", total) #\n",
    "        \n",
    "    return total/size_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_mean(q, GT):\n",
    "    part_1 = sum_P_R(q, GT)\n",
    "    part_2 = find_relevants(q, GT)\n",
    "    #print(\"part 1:\", part_1) #0.833\n",
    "    #print(\"part 2:\", part_2) #2\n",
    "    return float(part_1)/part_2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevants(q , GT):\n",
    "    relevants = 1\n",
    "    for j in range(len(GT)):\n",
    "        for i in range(len(q)):\n",
    "            if numeric_labels(q[i]) == numeric_labels(GT[i]):\n",
    "                relevants = relevants + 1\n",
    "  \n",
    "    return (relevants - 1)/(len(GT))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_P_R(q, GT):\n",
    "    \n",
    "    total = 0.0\n",
    "    \n",
    "    for j in range(len(GT)):\n",
    "        #print(j)\n",
    "        for i in range(len(q)):\n",
    "            pre = P(q, GT[j], i+1)\n",
    "            r = R(q[i], GT[j])\n",
    "            total = total + ( pre * r)\n",
    "            #print(\"i, P\",i, pre)\n",
    "            #print(\"r: \", r)\n",
    "            #print(\"totat_pr\", total)\n",
    "    #print(\"total\", total/len(GT)) #0.833\n",
    "    return total/len(GT)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = []\n",
    "i = 1\n",
    "    # r=root, d=directories, f = files\n",
    "for r, d, f in os.walk('/home/ozgu/Desktop/DATASETS/UCMerced_LandUse/train/'):\n",
    "    if i == 1:\n",
    "        dir_list = d\n",
    "        break\n",
    "\n",
    "print(\"done: \", sorted(dir_list))\n",
    "\n",
    "sorted_list = sorted(dir_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def numeric_labels(element):\n",
    "    element = str(element).split(\"_\")\n",
    "   # print(element[0])\n",
    "   \n",
    "    if element[0] == sorted_list[0]:\n",
    "        return 1\n",
    "    elif element[0] == sorted_list[1]:\n",
    "        return 2\n",
    "    elif element[0] == sorted_list[2]:\n",
    "        return 3\n",
    "    elif element[0] == sorted_list[3]:\n",
    "        return 4\n",
    "    elif element[0] == sorted_list[4]:\n",
    "        return 5\n",
    "    elif element[0] == sorted_list[5]:\n",
    "        return 6\n",
    "    elif element[0] == sorted_list[6]:\n",
    "        return 7\n",
    "    elif element[0] == sorted_list[7]:\n",
    "        return 8\n",
    "    elif element[0] == sorted_list[8]:\n",
    "        return 9\n",
    "    elif element[0] == sorted_list[9]:\n",
    "        return 10\n",
    "    elif element[0] == sorted_list[10]:\n",
    "        return 11\n",
    "    elif element[0] == sorted_list[11]:\n",
    "        return 12\n",
    "    elif element[0] == sorted_list[12]:\n",
    "        return 13\n",
    "    elif element[0] == sorted_list[13]:\n",
    "        return 14\n",
    "    elif element[0] == sorted_list[14]:\n",
    "        return 15\n",
    "    elif element[0] == sorted_list[15]:\n",
    "        return 16\n",
    "    elif element[0] == sorted_list[16]:\n",
    "        return 17\n",
    "    elif element[0] == sorted_list[17]:\n",
    "        return 18\n",
    "    elif element[0] == sorted_list[18]:\n",
    "        return 19\n",
    "    elif element[0] == sorted_list[19]:\n",
    "        return 20\n",
    "    elif element[0] == sorted_list[20]:\n",
    "        return 21\n",
    "    else:\n",
    "        return 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(q, ground_element, pos):\n",
    "    true_s = 0\n",
    "    false_s = 0\n",
    "    \n",
    "    for i in range(pos):\n",
    "        if numeric_labels(q[i]) == numeric_labels(ground_element):\n",
    "            true_s = true_s + 1\n",
    "            #print(\"true :\" ,true_s)\n",
    "      \n",
    "            #print(\"wrong match!\", true_s)\n",
    "           \n",
    "        \n",
    "    \n",
    "    \n",
    "    return float(true_s)/float(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R(element, ground_element):\n",
    "    if numeric_labels(element) == numeric_labels(ground_element):\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_query = []\n",
    "all_GT = []\n",
    "all_query.append(r) # for retrieved image list\n",
    "#all_query.append(r)\n",
    "\n",
    "all_GT.append(GT) #for GT's\n",
    "\n",
    "print(len(all_query))\n",
    "\n",
    "print(all_query[0])\n",
    "print(type(GT))\n",
    "print(type(r))\n",
    "print(new_MAP(all_query, all_GT))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total prediction for retrieval\n",
    "# for p@k ;\n",
    "# all images in a query if k = len(GT[i])\n",
    "# first m images in a query if k = m\n",
    "def pre(all_query, all_GT):\n",
    "    pred = 0.0\n",
    "    \n",
    "    for j in range(len(all_query)):\n",
    "        q = all_query[j]\n",
    "        GT = all_GT[j]\n",
    "        \n",
    "        for i in range(len(GT)):\n",
    "            pred = pred + P(q, GT[i], len(GT))\n",
    "\n",
    "    \n",
    "    return pred/len(all_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "new_gt = [0,1,1,0]\n",
    "new_r = [1,1,1,1]\n",
    "print(new_r)\n",
    "#for all functions (y_true, y_pred)\n",
    "print(accuracy_score(new_gt, new_r))\n",
    "#p-r-fscore\n",
    "a = precision_recall_fscore_support(new_gt, new_r, average='macro')\n",
    "print(precision_recall_fscore_support(new_gt, new_r, average='macro'))\n",
    "print(a[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('/home/ozgu/Desktop/DATASETS/UCMerced_LandUse/train/agricultural/agricultural12.jpg',0) #reads image data\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_list(array_num): \n",
    "    num_list = array_num.tolist() # list \n",
    "    print(num_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# importing required libraries of opencv \n",
    "import cv2 \n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# importing library for plotting \n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "\n",
    "# reads an input image \n",
    "img = cv2.imread('/home/ozgu/Desktop/DATASETS/UCMerced_LandUse/train/agricultural/agricultural12.jpg') \n",
    "b = np.zeros(256, dtype=np.int)\n",
    "color = ('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "    #print((np.reshape(histr.astype(int), (256))))\n",
    "    \n",
    "    \n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.title(\"RGB_histogram\")\n",
    "plt.show()\n",
    "# find frequency of pixels in range 0-255 \n",
    "\n",
    "# reads an input image \n",
    "\n",
    "# show the plotting graph of an image \n",
    "plt.plot(histr) \n",
    "plt.title(\"gray_histogram\")\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(feat, name):\n",
    "    file = open(name,\"a\")\n",
    "    \n",
    "    for i  in range(len(feat)):\n",
    "        file.write(str(feat[i]))\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "    return \"done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_name(string):\n",
    "    return os.path.basename(string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b4f9d5c9c236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi_all\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistogram_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistogram_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_all\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchi_square_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;31m#print(\"distance:\" ,distance)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mall_distance_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cab1ab62de26>\u001b[0m in \u001b[0;36mchi_square_distance\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchi_square_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "histogram_all = [] # histograms of all images in given directory\n",
    "image_name = [] # all image names in given directory\n",
    "all_distance_q = [] # all distance values (one query)\n",
    "files = []\n",
    "sim_image_name = [] # image names after distance calculation (one query)\n",
    "\n",
    "all_sim_all_hist = [] # for all query image names\n",
    "all_distance_all_hist = [] # for all distance results \n",
    "\n",
    "path = '/home/ozgu/Desktop/DATASETS/UCMerced_LandUse/train_all/'\n",
    "\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(files)):\n",
    "    img = cv2.imread(files[i],0)  # read image\n",
    "    #print(find_name(files[i]))\n",
    "    image_name.append(find_name(files[i]))# find the name of image\n",
    "    \n",
    "    histr = cv2.calcHist([img],[0],None,[256],[0,256])  # histogram\n",
    "    hist_arr = np.reshape(histr.astype(int), (256)) \n",
    "    histogram_all.append(hist_arr) \n",
    "    \n",
    "\n",
    "#print(histogram_all[4])\n",
    "#print(image_name[4])\n",
    "\n",
    "\n",
    "#similarity/ distance\n",
    "for i_test  in range(len(histogram_all)):\n",
    "    test = histogram_all[i_test]\n",
    "    all_distance_q = []  \n",
    "    sim_image_name = []\n",
    "    i_name = image_name[i_test]\n",
    "    \n",
    "    for i_all  in range(len(histogram_all)):\n",
    "        temp = histogram_all[i_all]\n",
    "        distance = chi_square_distance(test, temp)\n",
    "        #print(\"distance:\" ,distance)\n",
    "        all_distance_q.append(distance)\n",
    "        sim_image_name.append(image_name[i_all])\n",
    "        \n",
    "    #write(sim_image_name,i_name+ \"_n.txt\")\n",
    "    #write(all_distance_q,i_name + \"_d.txt\")\n",
    "        \n",
    "    all_sim_all_hist.append(sim_image_name)\n",
    "    all_distance_all_hist.append(all_distance_q)\n",
    "    \n",
    "    \n",
    "    # initialize list of lists \n",
    "    data = {'Image_name': sim_image_name, 'Distance': all_distance_q} \n",
    "\n",
    "    # Create the pandas DataFrame \n",
    "    df = pd.DataFrame(data, columns = ['Image_name', 'Distance']) \n",
    "\n",
    "    #sort\n",
    "    new_df = df.sort_values(by=['Distance'])\n",
    "   \n",
    "    new_df.to_csv(i_name + \".csv\", sep=',',index=True)\n",
    "    \n",
    "   \n",
    "    #print(saved_column[3])\n",
    "    \n",
    "print(\"names : \" ,len(all_sim_all_hist))\n",
    "print(\"all_ distance : \",len(all_distance_all_hist))\n",
    "\n",
    "#print(\"1- names : \" ,all_sim_all_hist[1])\n",
    "#print(\"1- all_ distance : \",all_distance_all_hist[1])\n",
    "\n",
    "#img = cv2.imread('/home/ozgu/Desktop/DATASETS/UCMerced_LandUse/train/agricultural/agricultural12.jpg',0) #\n",
    "\n",
    "#histr = cv2.calcHist([img],[0],None,[256],[0,256]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_zero_GT(GT_temp, class_len, length):\n",
    "    l = []\n",
    "    \n",
    "    for i in range(length):\n",
    "        if i <= class_len:\n",
    "            l.append(1)\n",
    "        else:\n",
    "            l.append(0)\n",
    "            \n",
    "    #print(\"GT : \", len(l))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_zero(temp, class_name):\n",
    "    l = []\n",
    "    \n",
    "    for i in range(len(temp)):\n",
    "        element = temp[i].split(\".\")\n",
    "        \n",
    "        element_n = element[0]\n",
    "        #print(\"cname \", class_name)\n",
    "        #print(\"temp \", element_n[0:len(element_n) - 2])\n",
    "        if element_n[0:len(element_n) - 2] == class_name:\n",
    "            l.append(1)\n",
    "        else:\n",
    "            l.append(-1)\n",
    "    #print(\"pred : \", len(l))        \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = '/home/ozgu/Desktop/EXP/shallow_methods/histogram_ucm/'\n",
    "\n",
    "# ['agricultural', 'airplane', 'baseballdiamond', 'beach', 'buildings', 'chaparral', 'denseresidential', \n",
    "# 'forest', 'freeway', 'golfcourse', 'harbor', 'intersection', 'mediumresidential', 'mobilehomepark', \n",
    "# 'overpass', 'parkinglot', 'river', 'runway', 'sparseresidential', 'storagetanks', 'tenniscourt']\n",
    "\n",
    "#total_class_sample = [87, 86, 84, 85, 84, 85, 84, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86 ]\n",
    "total_class_sample = [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86 ]\n",
    "files = []\n",
    "\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.csv' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "            \n",
    "print(len(files))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d9b2c2f43849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m#print(\"4\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mp_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_all\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mfind_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_one_zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mf1_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_all\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_one_zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-faff95943a29>\u001b[0m in \u001b[0;36mf1\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(\"P: \", P, \"R:\" ,R)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-cf9b03570a9c>\u001b[0m in \u001b[0;36mfind_recall\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mFN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_FN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['agricultural', 'airplane', 'baseballdiamond', 'beach', 'buildings', 'chaparral', 'denseresidential', 'forest', 'freeway', 'golfcourse', 'harbor', 'intersection', 'mediumresidential', 'mobilehomepark', \n",
    "               'overpass', 'parkinglot', 'river', 'runway', 'sparseresidential', 'storagetanks', 'tenniscourt']\n",
    "temp = []\n",
    "\n",
    "total_map = 0.0\n",
    "total_anmrr = 0.0\n",
    "\n",
    "total_p = 0.0\n",
    "total_f1 = 0.0\n",
    "total_acc = 0.0\n",
    "\n",
    "\n",
    "\n",
    "for i_class in range(len(class_names)):\n",
    "    class_name = class_names[i_class]\n",
    "    temp = []\n",
    "\n",
    "    all_query = []\n",
    "    all_GT = []\n",
    "\n",
    "    # They hold labels as 0,1 \n",
    "    #1:correct, 0: incorrect\n",
    "    all_GT_TF = [] \n",
    "    all_query_TF = []\n",
    "\n",
    "    p_one = 0.0\n",
    "    r_one = 0.0\n",
    "    f1_one = 0.0\n",
    "\n",
    "    p_all = 0.0\n",
    "    f1_all = 0.0\n",
    "\n",
    "    acc_one = 0.0\n",
    "   #print(len(files))\n",
    "    \n",
    "    for i in range(len(files)):\n",
    "        GT_temp = []\n",
    "        df = pd.read_csv(files[i])\n",
    "        #print(\"1\")\n",
    "        saved_column = df['Image_name'] \n",
    "        temp = saved_column.values.tolist()\n",
    "        #print(\"temp\",temp)\n",
    "        all_query.append(temp)\n",
    "        all_query_TF.append(one_zero(temp, class_name))\n",
    "        #print(\"2\")\n",
    "        #print(temp)\n",
    "        GT_temp = create_GT_new(total_class_sample[i_class],temp ,class_name)\n",
    "        #print (\"gt : \" , one_zero_GT(GT_temp, len(files)))\n",
    "        gt_one_zero = (one_zero_GT(GT_temp, total_class_sample[i_class] ,len(files)))\n",
    "        \n",
    "        all_GT_TF.append(gt_one_zero)\n",
    "       # print(\"GT temp\",GT_temp)\n",
    "        all_GT.append(GT_temp)\n",
    "        #print(\"3\")\n",
    "        #print(\"gt_one_zero \" , gt_one_zero)\n",
    "        #print(\" one_zero(temp, class_name) \",  one_zero(temp, class_name))\n",
    "        #print(\"gt_one_zero : \", gt_one_zero)\n",
    "        #print(\"pred : \", one_zero(temp, class_name))\n",
    "        \n",
    "       \n",
    "        #acc_one = acc_one + find_acc(gt_one_zero, one_zero(temp, class_name))\n",
    "        acc_one = acc_one + find_acc(gt_one_zero, one_zero(temp, class_name))\n",
    "        #print(\"4\")\n",
    "        p_all = p_all +  find_pre(gt_one_zero, one_zero(temp, class_name))\n",
    "        f1_all = f1_all +  f1(gt_one_zero, one_zero(temp, class_name))\n",
    "    \n",
    "    \n",
    "   # print(\"all_GT[9]: \",all_GT[9], \"all_QUERY[9]: \" , all_query[9] )\n",
    "    print(\"CLASS : \", class_name)\n",
    "    print(\"mAP : \", new_MAP(all_query_TF, all_GT_TF))\n",
    "    #print(\"mAP : \", MAP(all_query, all_GT))\n",
    "    print(\"ANMRR : \", ANMRR(all_query, all_GT))\n",
    "\n",
    "\n",
    "    print(\"P@all : \", p_all/len(files)) \n",
    "    print(\"f1 score : \", f1_all/len(files)) \n",
    "    print(\"Acc. : \", acc_one/len(files)) \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    total_map = total_map + new_MAP(all_query_TF, all_GT_TF)\n",
    "    total_anmrr = total_anmrr + ANMRR(all_query, all_GT)\n",
    "\n",
    "    total_p = total_p + (p_all/len(files))\n",
    "    total_f1 = total_f1 + (f1_all/len(files))\n",
    "    total_acc = total_acc + (acc_one/len(files))\n",
    "\n",
    "print(\"----TOTAL-----\")\n",
    "print(\"mAP : \", total_map/(len(class_names)))\n",
    "print(\"ANMRR : \", total_anmrr/(len(class_names)) )\n",
    "\n",
    "\n",
    "print(\"P@all : \",total_p/(len(class_names)) ) \n",
    "print(\"f1 score : \", total_f1/(len(class_names)) ) \n",
    "print(\"Acc. : \", total_acc/(len(class_names)) )    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_r_f1 come from sclearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['agricultural', 'airplane', 'baseballdiamond', 'beach', 'buildings', 'chaparral', 'denseresidential', 'forest', 'freeway', 'golfcourse', 'harbor', 'intersection', 'mediumresidential', 'mobilehomepark', \n",
    "               'overpass', 'parkinglot', 'river', 'runway', 'sparseresidential', 'storagetanks', 'tenniscourt']\n",
    "temp = []\n",
    "\n",
    "total_map = 0.0\n",
    "total_anmrr = 0.0\n",
    "\n",
    "total_p = 0.0\n",
    "total_f1 = 0.0\n",
    "total_acc = 0.0\n",
    "\n",
    "\n",
    "\n",
    "for i_class in range(len(class_names)):\n",
    "    class_name = class_names[i_class]\n",
    "    temp = []\n",
    "\n",
    "    all_query = []\n",
    "    all_GT = []\n",
    "\n",
    "    # They hold labels as 0,1 \n",
    "    #1:correct, 0: incorrect\n",
    "    all_GT_TF = [] \n",
    "    all_query_TF = []\n",
    "\n",
    "    p_one = 0.0\n",
    "    r_one = 0.0\n",
    "    f1_one = 0.0\n",
    "\n",
    "    p_all = 0.0\n",
    "    f1_all = 0.0\n",
    "\n",
    "    acc_one = 0.0\n",
    "   #print(len(files))\n",
    "    \n",
    "    for i in range(len(files)):\n",
    "        GT_temp = []\n",
    "        df = pd.read_csv(files[i])\n",
    "        #print(\"1\")\n",
    "        saved_column = df['Image_name'] \n",
    "        temp = saved_column.values.tolist()\n",
    "        #print(\"temp\",temp)\n",
    "        all_query.append(temp)\n",
    "        all_query_TF.append(one_zero(temp, class_name))\n",
    "        #print(\"2\")\n",
    "        #print(temp)\n",
    "        GT_temp = create_GT_new(total_class_sample[i_class],temp ,class_name)\n",
    "        #print (\"gt : \" , one_zero_GT(GT_temp, len(files)))\n",
    "        gt_one_zero = (one_zero_GT(GT_temp, total_class_sample[i_class] ,len(files)))\n",
    "        \n",
    "        all_GT_TF.append(gt_one_zero)\n",
    "       # print(\"GT temp\",GT_temp)\n",
    "        all_GT.append(GT_temp)\n",
    "        #print(\"3\")\n",
    "        #print(\"gt_one_zero \" , gt_one_zero)\n",
    "        #print(\" one_zero(temp, class_name) \",  one_zero(temp, class_name))\n",
    "        acc_one = acc_one + accuracy_score(gt_one_zero, one_zero(temp, class_name))\n",
    "\n",
    "        #p-r-fscore\n",
    "        all_prf1 = precision_recall_fscore_support(gt_one_zero, one_zero(temp, class_name), average='micro')\n",
    "        #print(\"4\")\n",
    "        p_all = p_all + all_prf1[0]\n",
    "        f1_all = f1_all + all_prf1[2]\n",
    "    \n",
    "    \n",
    "   # print(\"all_GT[9]: \",all_GT[9], \"all_QUERY[9]: \" , all_query[9] )\n",
    "    print(\"CLASS : \", class_name)\n",
    "    print(\"mAP : \", new_MAP(all_query_TF, all_GT_TF))\n",
    "    #print(\"mAP : \", MAP(all_query, all_GT))\n",
    "    print(\"ANMRR : \", ANMRR(all_query, all_GT))\n",
    "\n",
    "\n",
    "    print(\"P@all : \", p_all/len(files)) \n",
    "    print(\"f1 score : \", f1_all/len(files)) \n",
    "    print(\"Acc. : \", acc_one/len(files)) \n",
    "    \n",
    "    total_map = total_map + new_MAP(all_query_TF, all_GT_TF)\n",
    "    total_anmrr = total_anmrr + ANMRR(all_query, all_GT)\n",
    "\n",
    "    total_p = total_p + (p_all/len(files))\n",
    "    total_f1 = total_f1 + (f1_all/len(files))\n",
    "    total_acc = total_acc + (acc_one/len(files))\n",
    "\n",
    "print(\"----TOTAL-----\")\n",
    "print(\"mAP : \", total_map/(len(class_names)))\n",
    "print(\"ANMRR : \", total_anmrr/(len(class_names)) )\n",
    "\n",
    "\n",
    "print(\"P@all : \",total_p/(len(class_names)) ) \n",
    "print(\"f1 score : \", total_f1/(len(class_names)) ) \n",
    "print(\"Acc. : \", total_acc/(len(class_names)) )    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GT(len_class, query, class_name):\n",
    "    l = []\n",
    "    for i in range(len(query)):\n",
    "        if class_name in query[i]:\n",
    "            l.append(query[i])\n",
    "    \n",
    "    if len_class == len(l):\n",
    "        for i in range(len(query)):\n",
    "            if class_name in query[i]:\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                l.append(query[i])\n",
    "          \n",
    "    else:\n",
    "        print(\"something is wrong!\")\n",
    "        \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GT_new(len_class, query, class_name):\n",
    "    l = []\n",
    "    for i in range(len(query)):\n",
    "        if class_name in query[i]:\n",
    "            l.append(query[i])\n",
    "        \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = [[33,2,0,0,0,0,0,0,0,1,3], \n",
    "        [3,31,0,0,0,0,0,0,0,0,0], \n",
    "        [0,4,41,0,0,0,0,0,0,0,1], \n",
    "        [0,1,0,30,0,6,0,0,0,0,1], \n",
    "        [0,0,0,0,38,10,0,0,0,0,0], \n",
    "        [0,0,0,3,1,39,0,0,0,0,4], \n",
    "        [0,2,2,0,4,1,31,0,0,0,2],\n",
    "        [0,1,0,0,0,0,0,36,0,2,0], \n",
    "        [0,0,0,0,0,0,1,5,37,5,1], \n",
    "        [3,0,0,0,0,0,0,0,0,39,0], \n",
    "        [0,0,0,0,0,0,0,0,0,0,38]]\n",
    "\n",
    "df_cm = pd.DataFrame(array, index = [i for i in ['Tom', 'Jack', 'nick', 'juli', 'Tom', 'Jack', 'nick', 'juli','Tom', 'Jack', 'nick', 'juli','Tom', 'Jack', 'nick', 'juli','Tom', 'Jack', 'nick', 'juli']],\n",
    "                  columns = [i for i in \"abcdefghklmn\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_TP(y_true, y_pred):\n",
    "    c_TP = 0\n",
    "    # counts the number of true positives (y_true = 1, y_pred = 1)\n",
    "    for i in range(len(y_true)):\n",
    "        if ((y_true[i] == 1) & (y_pred[i] == 1)):\n",
    "                   c_TP = c_TP + 1\n",
    "                   \n",
    "    return c_TP\n",
    "\n",
    "def find_FN(y_true, y_pred):\n",
    "    c_FN = 0\n",
    "    # counts the number of false negatives (y_true = 1, y_pred = 0)\n",
    "    for i in range(len(y_true)):\n",
    "        if ((y_true[i] == 1) & (y_pred[i] == 0)):\n",
    "                   c_FN = c_FN + 1\n",
    "                   \n",
    "    return c_FN\n",
    "   \n",
    "def find_FP(y_true, y_pred):\n",
    "    # counts the number of false positives (y_true = 0, y_pred = 1)\n",
    "    c_FP = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if ((y_true[i] == 0) & (y_pred[i] == 1)):\n",
    "                   c_FP = c_FP + 1\n",
    "                   \n",
    "    return c_FP\n",
    "    \n",
    "def find_TN(y_true, y_pred):\n",
    "    # counts the number of true negatives (y_true = 0, y_pred = 0)\n",
    "    c_TN = 0\n",
    " \n",
    "    for i in range(len(y_true)):\n",
    "        if ((y_true[i] == 0) & (y_pred[i] == 0)):\n",
    "                   c_TN = c_TN + 1\n",
    "                   \n",
    "    return c_TN\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pre(y_true, y_pred):\n",
    "    TP = find_TP(y_true, y_pred)\n",
    "    FP = find_FP(y_true, y_pred)\n",
    "    \n",
    "    return (float)(TP)/ (float)(TP + FP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recall(y_true, y_pred):\n",
    "    TP = find_TP(y_true, y_pred)\n",
    "    FN = find_FN(y_true, y_pred)\n",
    "    \n",
    "    return (float)(TP)/((float)(TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_acc(y_true, y_pred):\n",
    "    TP = find_TP(y_true, y_pred)\n",
    "    FP = find_FP(y_true, y_pred)\n",
    "    FN = find_FN(y_true, y_pred)\n",
    "    TN = find_TN(y_true, y_pred)\n",
    "    \n",
    "    return (float)(TP)/((float)(TP +TN + FP +FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    P = find_pre(y_true, y_pred)\n",
    "    R = find_recall(y_true, y_pred)\n",
    "    #print(\"P: \", P, \"R:\" ,R)\n",
    "    \n",
    "    if (P == 0) or (R == 0):\n",
    "        return 0.0\n",
    "    \n",
    "    return 2.0 * ((P * R)/(P + R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TP : ', 2)\n",
      "('FP : ', 2)\n",
      "('FN : ', 2)\n",
      "('TN : ', 1)\n",
      "0.5\n",
      "0.5\n",
      "0.571428571429\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"TP : \", find_TP([1,0,1,1,1,0,0],[1,1,1,0,0,0,1]))\n",
    "print(\"FP : \", find_FP([1,0,1,1,1,0,0],[1,1,1,0,0,0,1]))\n",
    "print(\"FN : \", find_FN([1,0,1,1,1,0,0],[1,1,1,0,0,0,1]))\n",
    "print(\"TN : \", find_TN([1,0,1,1,1,0,0],[1,1,1,0,0,0,1]))\n",
    "\n",
    "print(find_pre([1,0,1,1,1,0,0],[1,1,1,0,0,0,1]))\n",
    "print(find_recall([1,0,1,1,1,0,0],[1,1,1,0,0,0,1]))\n",
    "print(find_acc([1,0,1,1,1,0,0],[1,0,1,1,1,0,0]))\n",
    "print(f1([1,0,1,1,1,0,0],[1,1,1,0,0,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library \n",
    "import pandas as pd \n",
    "a = ['Tom', 'Jack', 'nick', 'juli']\n",
    "b = [99, 101, 95, 90]\n",
    "\n",
    "# initialize list of lists \n",
    "data = {'Image_name': sim_image_name, 'Distance': all_distance_q} \n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns = ['Image_name', 'Distance']) \n",
    "  \n",
    "# print dataframe. \n",
    "df \n",
    "\n",
    "\n",
    "\n",
    "new_df = df.sort_values(by=['Distance'])\n",
    "\n",
    "new_df.to_csv(\"file_name_n.csv\", sep=',',index=True)\n",
    "\n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
