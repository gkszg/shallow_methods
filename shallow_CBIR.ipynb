{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):   \n",
    "    return np.sqrt(np.sum((x - y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    return 1.0 - cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(x,y):\n",
    "    \n",
    "    return np.sum(np.absolute(x - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_distance(x,y):\n",
    "    return 0.5 * (np.sum(((x - y) ** 2) / (x + y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Q = 1\n",
    "CONST_K = 1.25\n",
    "CONST_ANMRR = 0.5\n",
    "GT = [1,4]  #must be name of samples\n",
    "r = [0,1,4,0,0,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANMRR(all_query,all_GT):\n",
    "    total = 0.0\n",
    "    \n",
    "    for q in range(len(all_query)):\n",
    "        total = total + one_sample_nmrr(all_query[q], all_GT[q])\n",
    "        print(\"ANMRR : \", total)\n",
    "        \n",
    "    return (1.0/len(all_query)) * total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sample_nmrr(q, GT):\n",
    "    part_1 = rank_mean(q, GT) - (CONST_ANMRR * (1.0 + len(GT)))\n",
    "    part_2 = (CONST_K * 2.0 * len(GT))- (CONST_ANMRR * (1.0 + len(GT)))\n",
    "    #print(\"rank_mean: \", rank_mean(q))\n",
    "    #print(\"part_1:\" , part_1)\n",
    "    #print(\"part_2:\" ,part_2)\n",
    "    return part_1/part_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_mean(q, GT):\n",
    "    const_q = len(GT)\n",
    "    #print(\"rank_m (cons_q) :\" , const_q )\n",
    "    #print(\"sum_rank_q: \",sum_rank_q(q))\n",
    "   \n",
    "    return (1.0/const_q)*sum_rank_q(q, GT)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_rank_q(q, GT):\n",
    "    \n",
    "    total_pos = 0.0\n",
    "    penalty = 2 * CONST_K * (len(GT))\n",
    "    const_size = 2 *  (len(GT))\n",
    "    #print(const_size)\n",
    "    for j in range(len(GT)):\n",
    "        if q.index(GT[j]) <= const_size:\n",
    "            total_pos = total_pos + q.index(GT[j])+1\n",
    "            #print(\"1\")\n",
    "        else:\n",
    "            total_pos = total_pos + penalty\n",
    "        #print(\"0\")\n",
    "                \n",
    "    print(\"total_pos : \" , total_pos)\n",
    "    return total_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0, 1, 4, 0, 0, 8]\n",
      "('total_pos : ', 5.0)\n",
      "('ANMRR : ', 0.2857142857142857)\n",
      "0.285714285714\n"
     ]
    }
   ],
   "source": [
    "all_query = []\n",
    "all_GT = []\n",
    "all_query.append(r) # for retrieved image list\n",
    "#all_query.append(r)\n",
    "\n",
    "all_GT.append(GT) #for GT's\n",
    "\n",
    "print(len(all_query))\n",
    "\n",
    "print(all_query[0])\n",
    "\n",
    "print(ANMRR(all_query, all_GT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP(x,y):\n",
    "    total = 0.0\n",
    "    size_Q = len(all_query)\n",
    "    \n",
    "    for q in range(len(all_query)):\n",
    "        total = total + precision_mean(all_query[q], all_GT[q])\n",
    "        #print(\"MAP : \", total) #0.4166\n",
    "        \n",
    "    return total/size_Q\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_mean(q, GT):\n",
    "    part_1 = sum_P_R(q, GT)\n",
    "    part_2 = find_relevants(q, GT)\n",
    "    #print(\"part 1:\", part_1) #0.833\n",
    "    #print(\"part 2:\", part_2) #2\n",
    "    return float(part_1)/part_2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevants(q , GT):\n",
    "    relevants = 0\n",
    "    for j in range(len(GT)):\n",
    "        for i in range(len(q)):\n",
    "            if numeric_labels(q[i]) == numeric_labels(GT[j]):\n",
    "                relevants = relevants + 1\n",
    "    #print(\"relevant : \",relevants)\n",
    "    return relevants/(len(GT))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_P_R(q, GT):\n",
    "    \n",
    "    total = 0.0\n",
    "    \n",
    "    for j in range(len(GT)):\n",
    "       # print(len(q))\n",
    "        for i in range(len(q)):\n",
    "            pre = P(q, GT[j], i+1)\n",
    "            r = R(q[i], GT[j])\n",
    "            total = total + ( pre * r)\n",
    "            #print(\"i, P\",i, pre)\n",
    "            #print(\"r: \", r)\n",
    "            #print(\"totat_pr\", total)\n",
    "   # print(\"total\", total/len(GT)) #0.833\n",
    "    return total/len(GT)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_labels(element):\n",
    "    if element == 4:\n",
    "        return 1\n",
    "    elif element == 5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(q, ground_element, pos):\n",
    "    true_s = 0\n",
    "    false_s = 0\n",
    "    \n",
    "    for i in range(pos):\n",
    "        if numeric_labels(q[i]) == numeric_labels(ground_element):\n",
    "            true_s = true_s + 1\n",
    "            #print(\"true :\" ,true_s)\n",
    "      \n",
    "            #print(\"wrong match!\", true_s)\n",
    "           \n",
    "        \n",
    "    \n",
    "    \n",
    "    return float(true_s)/float(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R(element, ground_element):\n",
    "    if numeric_labels(element) == numeric_labels(ground_element):\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0, 1, 1, 0, 0, 8]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "all_query = []\n",
    "all_GT = []\n",
    "all_query.append(r) # for retrieved image list\n",
    "#all_query.append(r)\n",
    "\n",
    "all_GT.append(GT) #for GT's\n",
    "\n",
    "print(len(all_query))\n",
    "\n",
    "print(all_query[0])\n",
    "\n",
    "print(MAP(all_query, all_GT))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total prediction for retrieval\n",
    "# for p@k ;\n",
    "# all images in a query if k = len(GT[i])\n",
    "# first m images in a query if k = m\n",
    "def pre(all_query, all_GT):\n",
    "    pred = 0.0\n",
    "    \n",
    "    for j in range(len(all_query)):\n",
    "        q = all_query[j]\n",
    "        GT = all_GT[j]\n",
    "        \n",
    "        for i in range(len(GT)):\n",
    "            pred = pred + P(q, GT[i], len(GT))\n",
    "\n",
    "    \n",
    "    return pred/len(all_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0]\n",
      "0.6\n",
      "(0.5833333333333333, 0.5833333333333333, 0.5833333333333333, None)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "new_gt = GT[:5]\n",
    "new_r = r[:5]\n",
    "print(new_r)\n",
    "#for all functions (y_true, y_pred)\n",
    "print(accuracy_score(new_gt, new_r))\n",
    "#p-r-fscore\n",
    "print(precision_recall_fscore_support(new_gt, new_r, average='macro'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
